import requests
import csv

def fetch_data_from_api(api_endpoint, bearer_token):
    headers = {
        "Authorization": f"Bearer {bearer_token}"
    }
    response = requests.get(api_endpoint, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Failed to fetch data from API")
        if response.status_code == 401:
            print(f"Apply proper Bearer token!, status code : {response.status_code}")
        else:
            print(f" status code : {response.status_code}")
        return None

def format_data_type(data_type):
    if data_type == "INTEGER" or data_type == "AUTO":
        return "numeric"
    elif data_type == "VARCHAR" or data_type == "TEXT":
        return "char"
    elif data_type == "TIMESTAMP" or data_type == "TIME_STAMP":
        return "datetime"
    elif "string_var" in data_type.lower():
        return "char"
    elif data_type == "auto":
        return "numeric"
    else:
        return data_type.lower()

def write_to_csv(data, filename):
    unique_tables = []
    related_table_data = []
    
    with open(filename, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['SPRICED_TABLE_NAME', 'Table_Display_Name', 'TABLE_SCHEMA', 'COLUMN_NAME', 'DISPLAY_NAME', 'DATA_TYPE', 'SIZE', 'POS', 'IS_NULLABLE', 'IS_REF_COLUMN', 'PRIMARY_KEY', 'AUTOGEN', 'Ref'])
        for entity in data:
            table_name = entity["name"]
            table_display_name = entity["displayName"] 
            entity_id = entity["id"]
            attributes = entity["attributes"]
            unique_tables.append((table_name, entity_id))
            for attribute in attributes:
                column_name = attribute["name"]
                if column_name.lower() in ['id', 'updated_date', 'comment', 'updated_by', 'is_valid', 'created_date', 'created_by', 'validationstatus']:
                    continue
                display_name = attribute["displayName"]
                data_type = format_data_type(attribute["dataType"])
                size = attribute.get("size", None)
                pos = attribute.get("numberOfDecimalValues", None)
                is_nullable = "no" if not attribute["nullable"] else "yes"
                is_ref_column = "TRUE" if attribute["type"] == "LOOKUP" else "FALSE"
                primary_key = ""
                if attribute["constraintType"] == "UNIQUE_KEY":
                    primary_key = "UK"
                elif attribute["constraintType"] == "FOREIGN_KEY":
                    primary_key = "FK"
                elif attribute["constraintType"] == "PRIMARY_KEY":
                    primary_key = "PK"
                autogen = "true" if attribute["autoGenerated"] else ""
                ref = attribute.get("referencedTable", "")
                
                writer.writerow([table_name, table_display_name, 'spriced', column_name, display_name, data_type, size, pos, is_nullable, is_ref_column, primary_key, autogen, ref])
                
                if ref:
                    related_table_data.append([table_name, column_name, display_name, ref])
    
    print(f"All table details written to -> {filename} ,successfully!")

    # Write related_table.csv
    with open('related_tables.csv', mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['entity_name', 'columns', 'display_name', 'linked_to'])
        for row in related_table_data:
            writer.writerow(row)
    
    print(f"All related table details written to -> related_tables.csv ,successfully!")

    # Sort the unique tables by entity_id
    sorted_unique_tables = sorted(unique_tables, key=lambda x: x[1])
    
    # Write sequence_tables.csv
    with open('sequence_tables.csv', mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['json_name', 'Sequence of Ingestion'])
        for table_name, entity_id in sorted_unique_tables:
            writer.writerow([table_name, entity_id])
    
    print(f"All unique table names written to -> sequence_tables.csv ,successfully!")

def main():
    api_endpoint = "https://spriced.meritor.uat.simadvisory.com/api/v1/definition/models/1/entities"
    bearer_token = "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJDYTZ5YnhvRWhLZ09haHE2U1lWWWxPdFJhSWdRaVYxSFplcmFwOWxBcHNFIn0.eyJleHAiOjE3MTcxNDA0ODAsImlhdCI6MTcxNzA3MDkxOSwiYXV0aF90aW1lIjoxNzE3MDU0MDgwLCJqdGkiOiIxZGZjMjJlZi00ZWIyLTRhYWItOWIwYy05NWRhYTY0MzcyNjYiLCJpc3MiOiJodHRwczovL2F1dGguZGV2LnNpbWFkdmlzb3J5LmNvbS9hdXRoL3JlYWxtcy9EX1NQUklDRUQiLCJhdWQiOiJhY2NvdW50Iiwic3ViIjoiMDE0ZjI2YzMtMTA2NS00ZGUwLTgxMzMtN2ZmZGJjZWYxZWMyIiwidHlwIjoiQmVhcmVyIiwiYXpwIjoiRF9TUFJJQ0VEX0NsaWVudCIsIm5vbmNlIjoiOWY5MTc0MmItOGUyNi00Zjg1LTlhOGQtMGY0MjI3NTk1MmZlIiwic2Vzc2lvbl9zdGF0ZSI6ImNmNmE5ZTdjLWMzYmYtNDc5Mi1iMTBjLTFjZmVmYWE0Y2I4NCIsImFjciI6IjAiLCJhbGxvd2VkLW9yaWdpbnMiOlsiaHR0cDovL2xvY2FsaG9zdDo0MjA0IiwiaHR0cHM6Ly9zcHJpY2VkLmRldi5zaW1hZHZpc29yeS5jb20iLCJodHRwOi8vbG9jYWxob3N0OjQyMDIiLCJodHRwOi8vbG9jYWxob3N0OjQyMDEiLCIqIiwiaHR0cHM6Ly9zcHJpY2VkLm1lcml0b3IudWF0LnNpbWFkdmlzb3J5LmNvbSIsImh0dHBzOi8vd3d3LnNpbWFkdmlzb3J5LmNvbTo0MjAwIiwiaHR0cDovL2xvY2FsaG9zdDo0MjAwIiwiaHR0cHM6Ly9zcHJpY2VkLnRlc3Quc2ltYWR2aXNvcnkuY29tIiwiaHR0cHM6Ly9leGNlbHBsdWdpbi5yb3V0ZS5tZXJpdG9yLnVhdC5zaW1hZHZpc29yeS5jb20iLCJodHRwczovL3BkbS5zaW1hZHZpc29yeS5jb20iLCJodHRwczovL2xvY2FsaG9zdDozMDAwIiwiaHR0cHM6Ly80NjMzLTEyMi0xNjUtMTY5LTIzNS5uZ3Jvay1mcmVlLmFwcCIsImh0dHBzOi8vc3ByaWNlZC5kZXYubWVyaXRvci5zaW1hZHZpc29yeS5jb20iLCJodHRwczovL3JlcG9ydHMuc3ByaWNlZC5kZXYuc2ltYWR2aXNvcnkuY29tIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJkZWZhdWx0LXJvbGVzLWRfc3ByaWNlZCIsIkFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgcm9sZXMgcHJvZmlsZSBlbWFpbCIsInNpZCI6ImNmNmE5ZTdjLWMzYmYtNDc5Mi1iMTBjLTFjZmVmYWE0Y2I4NCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6Ik1vaGQgSHVzc2FpbiIsInByZWZlcnJlZF91c2VybmFtZSI6Imh1c3NhaW4iLCJnaXZlbl9uYW1lIjoiTW9oZCIsImZhbWlseV9uYW1lIjoiSHVzc2FpbiIsInRlbmFudCI6Im1lcml0b3IiLCJlbWFpbCI6Im1vaGQuaHVzYWluQHNpbWFkdmlzb3J5cGFydG5lci5jb20ifQ.Vfr5-Sn5lUfmy2PbaG26tvzIV73SYd5iCT6ifv6ao8r0m7bkY0sJTW-V8PPNCnp3LNEL3S_UdNR-aaFYJC6MGcpxJW-RJs-vgqEYk4tYTl83vIRoUWIuhOsaAgkZ4YhLtVcpiyGQnXrJoAZCfJ27ujcZn1kNzX2Jz5L5Z9QqC-gylQ0vjf56rdTwAoNlUR0ArIbjjDZnpUaYX7XJg8sllJrkbDG7k3tsLC3-Zfc3UnnumY6CXWejwA0kB09Em_tnB3Gh6cStEx44nDyS4LsaPd-8M0OVwD5kwG7MKhnoSXnvZWtcUZnbV8PnFmExVcn24CGe4BsPWRjjtoaa_8quog"  # Replace with your actual bearer token
    data = fetch_data_from_api(api_endpoint, bearer_token)
    if data:
        write_to_csv(data, "sourceDataGen.csv")
    else:
        print("No data fetched from the API.")

if __name__ == "__main__":
    main()
